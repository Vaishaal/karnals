{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from importlib import reload\n",
    "import multigpu\n",
    "reload(multigpu)\n",
    "import utils\n",
    "reload(utils)\n",
    "import numpy as np\n",
    "import opt\n",
    "reload(opt)\n",
    "from opt import trainAndEvaluatePrimalModel, trainAndEvaluateDualModel, computeRBFGramMatrix, computeDistanceMatrix\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "from numba import jit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ARE_YOU_SURE = False\n",
    "\n",
    "def switch_output_to_notebook():\n",
    "    sys.stdout = notebook_stdout\n",
    "    sys.stderr = notebook_stdout\n",
    "\n",
    "def switch_output_to_terminal():\n",
    "    sys.stdout = terminal_stdout\n",
    "    sys.stderr = terminal_stderr\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU ARE NOT SURE YOU DUMMY\n"
     ]
    }
   ],
   "source": [
    "if (ARE_YOU_SURE):\n",
    "    print(\"DELETING ALL RESULTS YOU HAVE 10 seconds to ctrl-c\")\n",
    "    notebook_stdout = sys.stdout\n",
    "    notebook_stderr = sys.stderr\n",
    "    terminal_stdout = open('/dev/stdout', 'w')\n",
    "    terminal_stderr = open('/dev/stderr', 'w')\n",
    "    time.sleep(10)\n",
    "    # PUT CRITICAL CLEARING CODE HERE\n",
    "    results = []\n",
    "    features = []\n",
    "else:\n",
    "    print(\"YOU ARE NOT SURE YOU DUMMY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should take around 10 minutes\n",
    "%time train_df = pd.read_csv(\"full_genomics/deepsea_full_train.csv\")\n",
    "%time test_df = pd.read_csv(\"full_genomics/deepsea_full_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 948 ms, sys: 32 ms, total: 980 ms\n",
      "Wall time: 975 ms\n"
     ]
    }
   ],
   "source": [
    "%time eval_df = pd.read_csv(\"full_genomics/deepsea_full_eval.csv\")\n",
    "\n",
    "tfs = list(map(lambda x: x.split(\"|\")[0], list(train_df.columns[1:])))\n",
    "cell_types = list(map(lambda x: x.split(\"|\")[1], list(train_df.columns[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATASET = \"GM12878|Egr-1|None\"\n",
    "SEED = 0\n",
    "SEQ_SIZE = 300\n",
    "NUM_FEATURES = 8192\n",
    "GAMMA = 1.0\n",
    "KMER_SIZE = 8\n",
    "FEATS_TO_USE = 16384\n",
    "LAMBDA = 1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_full = train_df[DATASET].as_matrix()\n",
    "y_eval = eval_df[DATASET].as_matrix()\n",
    "y_test = test_df[DATASET].as_matrix()\n",
    "all_seqs_train = train_df[\"Sequence\"]\n",
    "all_seqs_test = test_df[\"Sequence\"]\n",
    "all_seqs_eval = eval_df[\"Sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "y_train_pos = y_train_full[y_train_full == 1]\n",
    "y_train_neg_locs = np.random.choice(np.where(y_train_full == 0)[0], y_train_pos.shape[0], replace=False)\n",
    "y_train = np.hstack((y_train_pos, y_train_full[y_train_neg_locs]))\n",
    "seqs_train = pd.concat((all_seqs_train[y_train_full == 1], all_seqs_train[y_train_neg_locs]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_seqs_train = seqs_train.str.slice(500 - SEQ_SIZE//2, 500 + SEQ_SIZE//2).tolist()\n",
    "x_seqs_eval = all_seqs_eval.str.slice(500 - SEQ_SIZE//2, 500 + SEQ_SIZE//2).tolist()\n",
    "x_seqs_test = all_seqs_test.str.slice(500 - SEQ_SIZE//2, 500 + SEQ_SIZE//2).tolist()\n",
    "\n",
    "X_train = utils.convertSeqToMatrix(x_seqs_train)\n",
    "X_eval = utils.convertSeqToMatrix(x_seqs_eval)\n",
    "X_test = utils.convertSeqToMatrix(x_seqs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 7: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "Using gpu device 2: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 13: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 12: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "Using gpu device 10: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 5: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 4: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "Using gpu device 3: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 15: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 1: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 14: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 11: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 6: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu2 512 (60508, 1024)\n",
      "gpu7 512 (60508, 1024)\n",
      "gpu13 512 (60508, 1024)\n",
      "gpu10 512 (60508, 1024)\n",
      "gpu12 512 (60508, 1024)\n",
      "gpu0 512 (60508, 1024)\n",
      "gpu5 512 (60508, 1024)\n",
      "gpu4 512 (60508, 1024)\n",
      "gpu3 512 (60508, 1024)\n",
      "gpu15 512 (60508, 1024)\n",
      "gpu1 512 (60508, 1024)\n",
      "gpu11 512 (60508, 1024)\n",
      "gpu6 512 (60508, 1024)\n",
      "gpu14 512 (60508, 1024)\n",
      "1\n",
      "1\n",
      "gpu2 Feature Batch  0\n",
      "gpu7 Feature Batch  0\n",
      "gpu2 Data Batch  0\n",
      "gpu7 Data Batch  0\n",
      "1\n",
      "gpu13 Feature Batch  0\n",
      "gpu13 Data Batch  0\n",
      "1\n",
      "1\n",
      "gpu12 Feature Batch  0\n",
      "gpu10 Feature Batch  0\n",
      "gpu12 Data Batch  0\n",
      "gpu10 Data Batch  0\n",
      "1\n",
      "1\n",
      "gpu0 Feature Batch  0\n",
      "gpu5 Feature Batch  0\n",
      "gpu5 Data Batch  0\n",
      "gpu0 Data Batch  0\n",
      "1\n",
      "1\n",
      "gpu15 Feature Batch  0\n",
      "gpu14 Feature Batch  0\n",
      "gpu14 Data Batch  0\n",
      "gpu15 Data Batch  0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "gpu4 Feature Batch  0\n",
      "gpu11 Feature Batch  0\n",
      "gpu3 Feature Batch  0\n",
      "gpu6 Feature Batch  0\n",
      "gpu1 Feature Batch  0\n",
      "gpu4 Data Batch  0\n",
      "gpu11 Data Batch  0\n",
      "gpu3 Data Batch  0\n",
      "gpu6 Data Batch  0\n",
      "gpu1 Data Batch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 9: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "Using gpu device 8: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu8 512 (60508, 1024)\n",
      "gpu9 512 (60508, 1024)\n",
      "1\n",
      "1\n",
      "gpu9 Feature Batch  0\n",
      "gpu8 Feature Batch  0\n",
      "gpu9 Data Batch  0\n",
      "gpu8 Data Batch  0\n",
      "gpu7 Data Batch  1\n",
      "gpu0 Data Batch  1\n",
      "gpu2 Data Batch  1\n",
      "gpu11 Data Batch  1\n",
      "gpu10 Data Batch  1\n",
      "gpu14 Data Batch  1\n",
      "gpu6 Data Batch  1\n",
      "gpu15 Data Batch  1\n",
      "gpu2 Data Batch  2\n",
      "gpu13 Data Batch  1\n",
      "gpu7 Data Batch  2\n",
      "gpu0 Data Batch  2\n",
      "gpu1 Data Batch  1\n",
      "gpu11 Data Batch  2\n",
      "gpu15 Data Batch  2\n",
      "gpu10 Data Batch  2\n",
      "gpu14 Data Batch  2\n",
      "gpu6 Data Batch  2\n",
      "gpu3 Data Batch  1\n",
      "gpu9 Data Batch  1\n",
      "gpu12 Data Batch  1\n",
      "gpu5 Data Batch  1\n",
      "gpu8 Data Batch  1\n",
      "gpu4 Data Batch  1\n",
      "gpu11 Data Batch  3\n",
      "gpu2 Data Batch  3\n",
      "gpu13 Data Batch  2\n",
      "gpu10 Data Batch  3\n",
      "gpu7 Data Batch  3\n",
      "gpu15 Data Batch  3\n",
      "gpu0 Data Batch  3\n",
      "gpu1 Data Batch  2\n",
      "gpu5 Data Batch  2\n",
      "gpu9 Data Batch  2\n",
      "gpu14 Data Batch  3\n",
      "gpu6 Data Batch  3\n",
      "gpu12 Data Batch  2\n",
      "gpu3 Data Batch  2\n",
      "gpu8 Data Batch  2\n",
      "gpu4 Data Batch  2\n",
      "gpu11 Data Batch  4\n",
      "gpu2 Data Batch  4\n",
      "gpu15 Data Batch  4\n",
      "gpu13 Data Batch  3\n",
      "gpu7 Data Batch  4\n",
      "gpu10 Data Batch  4\n",
      "gpu0 Data Batch  4\n",
      "gpu1 Data Batch  3\n",
      "gpu5 Data Batch  3\n",
      "gpu6 Data Batch  4\n",
      "gpu12 Data Batch  3\n",
      "gpu9 Data Batch  3\n",
      "gpu14 Data Batch  4\n",
      "gpu8 Data Batch  3\n",
      "gpu3 Data Batch  3\n",
      "gpu4 Data Batch  3\n",
      "gpu11 Data Batch  5\n",
      "gpu2 Data Batch  5\n",
      "gpu15 Data Batch  5\n",
      "gpu7 Data Batch  5\n",
      "gpu0 Data Batch  5\n",
      "gpu5 Data Batch  4\n",
      "gpu13 Data Batch  4\n",
      "gpu10 Data Batch  5\n",
      "gpu6 Data Batch  5\n",
      "gpu1 Data Batch  4\n",
      "gpu9 Data Batch  4\n",
      "gpu12 Data Batch  4\n",
      "gpu3 Data Batch  4\n",
      "gpu8 Data Batch  4\n",
      "gpu14 Data Batch  5\n",
      "gpu4 Data Batch  4\n",
      "gpu11 Data Batch  6\n",
      "gpu2 Data Batch  6\n",
      "gpu15 Data Batch  6\n",
      "gpu7 Data Batch  6\n",
      "gpu0 Data Batch  6\n",
      "gpu5 Data Batch  5\n",
      "gpu1 Data Batch  5\n",
      "gpu10 Data Batch  6\n",
      "gpu6 Data Batch  6\n",
      "gpu13 Data Batch  5\n",
      "gpu9 Data Batch  5\n",
      "gpu3 Data Batch  5\n",
      "gpu12 Data Batch  5\n",
      "gpu8 Data Batch  5\n",
      "gpu14 Data Batch  6\n",
      "gpu4 Data Batch  5\n",
      "gpu7 Data Batch  7\n",
      "gpu15 Data Batch  7\n",
      "gpu11 Data Batch  7\n",
      "gpu2 Data Batch  7\n",
      "gpu5 Data Batch  6\n",
      "gpu13 Data Batch  6\n",
      "gpu0 Data Batch  7\n",
      "gpu6 Data Batch  7\n",
      "gpu1 Data Batch  6\n",
      "gpu9 Data Batch  6\n",
      "gpu10 Data Batch  7\n",
      "gpu3 Data Batch  6\n",
      "gpu12 Data Batch  6\n",
      "gpu8 Data Batch  6\n",
      "gpu14 Data Batch  7\n",
      "gpu4 Data Batch  6\n",
      "gpu2 Data Batch  8\n",
      "gpu7 Data Batch  8\n",
      "gpu11 Data Batch  8\n",
      "gpu15 Data Batch  8\n",
      "gpu5 Data Batch  7\n",
      "gpu6 Data Batch  8\n",
      "gpu13 Data Batch  7\n",
      "gpu0 Data Batch  8\n",
      "gpu3 Data Batch  7\n",
      "gpu10 Data Batch  8\n",
      "gpu1 Data Batch  7\n",
      "gpu8 Data Batch  7\n",
      "gpu9 Data Batch  7\n",
      "gpu12 Data Batch  7\n",
      "gpu14 Data Batch  8\n",
      "gpu4 Data Batch  7\n",
      "gpu2 Data Batch  9\n",
      "gpu5 Data Batch  8\n",
      "gpu11 Data Batch  9\n",
      "gpu7 Data Batch  9\n",
      "gpu6 Data Batch  9\n",
      "gpu15 Data Batch  9\n",
      "gpu13 Data Batch  8\n",
      "gpu0 Data Batch  9\n",
      "gpu3 Data Batch  8\n",
      "gpu10 Data Batch  9\n",
      "gpu8 Data Batch  8\n",
      "gpu9 Data Batch  8\n",
      "gpu1 Data Batch  8\n",
      "gpu12 Data Batch  8\n",
      "gpu14 Data Batch  9\n",
      "gpu4 Data Batch  8\n",
      "gpu5 Data Batch  9\n",
      "gpu2 Data Batch  10\n",
      "gpu15 Data Batch  10\n",
      "gpu0 Data Batch  10\n",
      "gpu11 Data Batch  10\n",
      "gpu7 Data Batch  10\n",
      "gpu13 Data Batch  9\n",
      "gpu3 Data Batch  9\n",
      "gpu6 Data Batch  10\n",
      "gpu10 Data Batch  10\n",
      "gpu14 Data Batch  10\n",
      "gpu1 Data Batch  9\n",
      "gpu12 Data Batch  9\n",
      "gpu8 Data Batch  9\n",
      "gpu9 Data Batch  9\n",
      "gpu4 Data Batch  9\n",
      "gpu5 Data Batch  10\n",
      "gpu2 Data Batch  11\n",
      "gpu15 Data Batch  11\n",
      "gpu11 Data Batch  11\n",
      "gpu3 Data Batch  10\n",
      "gpu0 Data Batch  11\n",
      "gpu13 Data Batch  10\n",
      "gpu14 Data Batch  11\n",
      "gpu10 Data Batch  11\n",
      "gpu6 Data Batch  11\n",
      "gpu7 Data Batch  11\n",
      "gpu9 Data Batch  10\n",
      "gpu1 Data Batch  10\n",
      "gpu12 Data Batch  10\n",
      "gpu8 Data Batch  10\n",
      "gpu4 Data Batch  10\n",
      "gpu2 Data Batch  12\n",
      "gpu11 Data Batch  12\n",
      "gpu5 Data Batch  11\n",
      "gpu15 Data Batch  12\n",
      "gpu3 Data Batch  11\n",
      "gpu0 Data Batch  12\n",
      "gpu7 Data Batch  12\n",
      "gpu6 Data Batch  12\n",
      "gpu14 Data Batch  12\n",
      "gpu10 Data Batch  12\n",
      "gpu13 Data Batch  11\n",
      "gpu9 Data Batch  11\n",
      "gpu12 Data Batch  11\n",
      "gpu1 Data Batch  11\n",
      "gpu8 Data Batch  11\n",
      "gpu4 Data Batch  11\n",
      "gpu11 Data Batch  13\n",
      "gpu3 Data Batch  12\n",
      "gpu15 Data Batch  13\n",
      "gpu2 Data Batch  13\n",
      "gpu5 Data Batch  12\n",
      "gpu9 Data Batch  12\n",
      "gpu14 Data Batch  13\n",
      "gpu13 Data Batch  12\n",
      "gpu7 Data Batch  13\n",
      "gpu0 Data Batch  13\n",
      "gpu10 Data Batch  13\n",
      "gpu6 Data Batch  13\n",
      "gpu12 Data Batch  12\n",
      "gpu1 Data Batch  12\n",
      "gpu8 Data Batch  12\n",
      "gpu4 Data Batch  12\n",
      "gpu2 Data Batch  14\n",
      "gpu11 Data Batch  14\n",
      "gpu15 Data Batch  14\n",
      "gpu5 Data Batch  13\n",
      "gpu3 Data Batch  13\n",
      "gpu0 Data Batch  14\n",
      "gpu14 Data Batch  14\n",
      "gpu9 Data Batch  13\n",
      "gpu7 Data Batch  14\n",
      "gpu13 Data Batch  13\n",
      "gpu12 Data Batch  13\n",
      "gpu10 Data Batch  14\n",
      "gpu6 Data Batch  14\n",
      "gpu1 Data Batch  13\n",
      "gpu4 Data Batch  13\n",
      "gpu8 Data Batch  13\n",
      "gpu2 Data Batch  15\n",
      "gpu11 Data Batch  15\n",
      "gpu3 Data Batch  14\n",
      "gpu15 Data Batch  15\n",
      "gpu5 Data Batch  14\n",
      "gpu0 Data Batch  15\n",
      "gpu9 Data Batch  14\n",
      "gpu12 Data Batch  14\n",
      "gpu13 Data Batch  14\n",
      "gpu7 Data Batch  15\n",
      "gpu1 Data Batch  14\n",
      "gpu10 Data Batch  15\n",
      "gpu14 Data Batch  15\n",
      "gpu6 Data Batch  15\n",
      "gpu4 Data Batch  14\n",
      "gpu8 Data Batch  14\n",
      "gpu2 Data Batch  16\n",
      "gpu3 Data Batch  15\n",
      "gpu0 Data Batch  16\n",
      "gpu15 Data Batch  16\n",
      "gpu11 Data Batch  16\n",
      "gpu5 Data Batch  15\n",
      "gpu9 Data Batch  15\n",
      "gpu7 Data Batch  16\n",
      "gpu1 Data Batch  15\n",
      "gpu10 Data Batch  16\n",
      "gpu6 Data Batch  16\n",
      "gpu12 Data Batch  15\n",
      "gpu14 Data Batch  16\n",
      "gpu13 Data Batch  15\n",
      "gpu8 Data Batch  15\n",
      "gpu4 Data Batch  15\n",
      "gpu2 Data Batch  17\n",
      "gpu5 Data Batch  16\n",
      "gpu0 Data Batch  17\n",
      "gpu15 Data Batch  17\n",
      "gpu9 Data Batch  16\n",
      "gpu3 Data Batch  16\n",
      "gpu11 Data Batch  17\n",
      "gpu7 Data Batch  17\n",
      "gpu1 Data Batch  16\n",
      "gpu8 Data Batch  16\n",
      "gpu14 Data Batch  17\n",
      "gpu13 Data Batch  16\n",
      "gpu6 Data Batch  17\n",
      "gpu10 Data Batch  17\n",
      "gpu12 Data Batch  16\n",
      "gpu4 Data Batch  16\n",
      "gpu2 Data Batch  18\n",
      "gpu5 Data Batch  17\n",
      "gpu3 Data Batch  17\n",
      "gpu15 Data Batch  18\n",
      "gpu0 Data Batch  18\n",
      "gpu7 Data Batch  18\n",
      "gpu11 Data Batch  18\n",
      "gpu9 Data Batch  17\n",
      "gpu1 Data Batch  17\n",
      "gpu10 Data Batch  18\n",
      "gpu13 Data Batch  17\n",
      "gpu14 Data Batch  18\n",
      "gpu12 Data Batch  17\n",
      "gpu4 Data Batch  17\n",
      "gpu6 Data Batch  18\n",
      "gpu8 Data Batch  17\n",
      "gpu5 Data Batch  18\n",
      "gpu2 Data Batch  19\n",
      "gpu9 Data Batch  18\n",
      "gpu3 Data Batch  18\n",
      "gpu13 Data Batch  18\n",
      "gpu1 Data Batch  18\n",
      "gpu15 Data Batch  19\n",
      "gpu11 Data Batch  19\n",
      "gpu7 Data Batch  19\n",
      "gpu10 Data Batch  19\n",
      "gpu0 Data Batch  19\n",
      "gpu6 Data Batch  19\n",
      "gpu8 Data Batch  18\n",
      "gpu12 Data Batch  18\n",
      "gpu4 Data Batch  18\n",
      "gpu14 Data Batch  19\n",
      "gpu2 Data Batch  20\n",
      "gpu5 Data Batch  19\n",
      "gpu9 Data Batch  19\n",
      "gpu3 Data Batch  19\n",
      "gpu7 Data Batch  20\n",
      "gpu1 Data Batch  19\n",
      "gpu6 Data Batch  20\n",
      "gpu0 Data Batch  20\n",
      "gpu11 Data Batch  20\n",
      "gpu13 Data Batch  19\n",
      "gpu15 Data Batch  20\n",
      "gpu10 Data Batch  20\n",
      "gpu14 Data Batch  20\n",
      "gpu8 Data Batch  19\n",
      "gpu4 Data Batch  19\n",
      "gpu12 Data Batch  19\n",
      "gpu2 Data Batch  21\n",
      "gpu3 Data Batch  20\n",
      "gpu5 Data Batch  20\n",
      "gpu9 Data Batch  20\n",
      "gpu7 Data Batch  21\n",
      "gpu1 Data Batch  20\n",
      "gpu10 Data Batch  21\n",
      "gpu0 Data Batch  21\n",
      "gpu11 Data Batch  21\n",
      "gpu6 Data Batch  21\n",
      "gpu15 Data Batch  21\n",
      "gpu13 Data Batch  20\n",
      "gpu8 Data Batch  20\n",
      "gpu14 Data Batch  21\n",
      "gpu4 Data Batch  20\n",
      "gpu12 Data Batch  20\n",
      "gpu2 Data Batch  22\n",
      "gpu3 Data Batch  21\n",
      "gpu5 Data Batch  21\n",
      "gpu9 Data Batch  21\n",
      "gpu1 Data Batch  21\n",
      "gpu7 Data Batch  22\n",
      "gpu0 Data Batch  22\n",
      "gpu11 Data Batch  22\n",
      "gpu15 Data Batch  22\n",
      "gpu6 Data Batch  22\n",
      "gpu13 Data Batch  21\n",
      "gpu10 Data Batch  22\n",
      "gpu12 Data Batch  21\n",
      "gpu8 Data Batch  21\n",
      "gpu4 Data Batch  21\n",
      "gpu14 Data Batch  22\n",
      "gpu3 Data Batch  22\n",
      "gpu2 Data Batch  23\n",
      "gpu5 Data Batch  22\n",
      "gpu9 Data Batch  22\n",
      "gpu7 Data Batch  23\n",
      "gpu1 Data Batch  22\n",
      "gpu0 Data Batch  23\n",
      "gpu15 Data Batch  23\n",
      "gpu6 Data Batch  23\n",
      "gpu13 Data Batch  22\n",
      "gpu11 Data Batch  23\n",
      "gpu10 Data Batch  23\n",
      "gpu14 Data Batch  23\n",
      "gpu12 Data Batch  22\n",
      "gpu4 Data Batch  22\n",
      "gpu8 Data Batch  22\n",
      "gpu3 Data Batch  23\n",
      "gpu2 Data Batch  24\n",
      "gpu5 Data Batch  23\n",
      "gpu9 Data Batch  23\n",
      "gpu1 Data Batch  23\n",
      "gpu7 Data Batch  24\n",
      "gpu0 Data Batch  24\n",
      "gpu10 Data Batch  24\n",
      "gpu15 Data Batch  24\n",
      "gpu6 Data Batch  24\n",
      "gpu11 Data Batch  24\n",
      "gpu13 Data Batch  23\n",
      "gpu12 Data Batch  23\n",
      "gpu14 Data Batch  24\n",
      "gpu4 Data Batch  23\n",
      "gpu8 Data Batch  23\n",
      "gpu3 Data Batch  24\n",
      "gpu2 Data Batch  25\n",
      "gpu5 Data Batch  24\n",
      "gpu9 Data Batch  24\n",
      "gpu1 Data Batch  24\n",
      "gpu7 Data Batch  25\n",
      "gpu0 Data Batch  25\n",
      "gpu13 Data Batch  24\n",
      "gpu15 Data Batch  25\n",
      "gpu11 Data Batch  25\n",
      "gpu6 Data Batch  25\n",
      "gpu10 Data Batch  25\n",
      "gpu12 Data Batch  24\n",
      "gpu4 Data Batch  24\n",
      "gpu8 Data Batch  24\n",
      "gpu14 Data Batch  25\n",
      "gpu3 Data Batch  25\n",
      "gpu2 Data Batch  26\n",
      "gpu5 Data Batch  25\n",
      "gpu9 Data Batch  25\n",
      "gpu7 Data Batch  26\n",
      "gpu0 Data Batch  26\n",
      "gpu1 Data Batch  25\n",
      "gpu13 Data Batch  25\n",
      "gpu6 Data Batch  26\n",
      "gpu10 Data Batch  26\n",
      "gpu15 Data Batch  26\n",
      "gpu11 Data Batch  26\n",
      "gpu12 Data Batch  25\n",
      "gpu4 Data Batch  25\n",
      "gpu14 Data Batch  26\n",
      "gpu3 Data Batch  26\n",
      "gpu8 Data Batch  25\n",
      "gpu2 Data Batch  27\n",
      "gpu5 Data Batch  26\n",
      "gpu9 Data Batch  26\n",
      "gpu7 Data Batch  27\n",
      "gpu0 Data Batch  27\n",
      "gpu13 Data Batch  26\n",
      "gpu1 Data Batch  26\n",
      "gpu6 Data Batch  27\n",
      "gpu10 Data Batch  27\n",
      "gpu15 Data Batch  27\n",
      "gpu11 Data Batch  27\n",
      "gpu12 Data Batch  26\n",
      "gpu4 Data Batch  26\n",
      "gpu2 Data Batch  28\n",
      "gpu14 Data Batch  27\n",
      "gpu8 Data Batch  26\n",
      "gpu3 Data Batch  27\n",
      "gpu5 Data Batch  27\n",
      "gpu7 Data Batch  28\n",
      "gpu9 Data Batch  27\n",
      "gpu13 Data Batch  27\n",
      "gpu6 Data Batch  28\n",
      "gpu10 Data Batch  28\n",
      "gpu0 Data Batch  28\n",
      "gpu1 Data Batch  27\n",
      "gpu15 Data Batch  28\n",
      "gpu4 Data Batch  27\n",
      "gpu12 Data Batch  27\n",
      "gpu11 Data Batch  28\n",
      "gpu2 Data Batch  29\n",
      "gpu8 Data Batch  27\n",
      "gpu3 Data Batch  28\n",
      "gpu14 Data Batch  28\n",
      "gpu9 Data Batch  28\n",
      "gpu5 Data Batch  28\n",
      "gpu7 Data Batch  29\n",
      "gpu6 Data Batch  29\n",
      "gpu13 Data Batch  28\n",
      "gpu0 Data Batch  29\n",
      "gpu10 Data Batch  29\n",
      "gpu1 Data Batch  28\n",
      "gpu15 Data Batch  29\n",
      "gpu4 Data Batch  28\n",
      "gpu12 Data Batch  28\n",
      "gpu11 Data Batch  29\n",
      "gpu2 Data Batch  30\n",
      "gpu14 Data Batch  29\n",
      "gpu3 Data Batch  29\n",
      "gpu8 Data Batch  28\n",
      "gpu9 Data Batch  29\n",
      "gpu7 Data Batch  30\n",
      "gpu5 Data Batch  29\n",
      "gpu13 Data Batch  29\n",
      "gpu6 Data Batch  30\n",
      "gpu0 Data Batch  30\n",
      "gpu1 Data Batch  29\n",
      "gpu10 Data Batch  30\n",
      "gpu15 Data Batch  30\n",
      "gpu2 Data Batch  31\n",
      "gpu12 Data Batch  29\n",
      "gpu11 Data Batch  30\n",
      "gpu4 Data Batch  29\n",
      "gpu3 Data Batch  30\n",
      "gpu8 Data Batch  29\n",
      "gpu14 Data Batch  30\n",
      "gpu9 Data Batch  30\n",
      "gpu5 Data Batch  30\n",
      "gpu13 Data Batch  30\n",
      "gpu6 Data Batch  31\n",
      "gpu7 Data Batch  31\n",
      "gpu0 Data Batch  31\n",
      "gpu1 Data Batch  30\n",
      "gpu10 Data Batch  31\n",
      "gpu15 Data Batch  31\n",
      "gpu2 Data Batch  32\n",
      "gpu4 Data Batch  30\n",
      "gpu11 Data Batch  31\n",
      "gpu12 Data Batch  30\n",
      "gpu3 Data Batch  31\n",
      "gpu14 Data Batch  31\n",
      "gpu8 Data Batch  30\n",
      "gpu9 Data Batch  31\n",
      "gpu5 Data Batch  31\n",
      "gpu7 Data Batch  32\n",
      "gpu0 Data Batch  32\n",
      "gpu6 Data Batch  32\n",
      "gpu13 Data Batch  31\n",
      "gpu1 Data Batch  31\n",
      "gpu10 Data Batch  32\n",
      "gpu15 Data Batch  32\n",
      "gpu2 Data Batch  33\n",
      "gpu11 Data Batch  32\n",
      "gpu4 Data Batch  31\n",
      "gpu12 Data Batch  31\n",
      "gpu3 Data Batch  32\n",
      "gpu9 Data Batch  32\n",
      "gpu5 Data Batch  32\n",
      "gpu8 Data Batch  31\n",
      "gpu14 Data Batch  32\n",
      "gpu7 Data Batch  33\n",
      "gpu0 Data Batch  33\n",
      "gpu1 Data Batch  32\n",
      "gpu6 Data Batch  33\n",
      "gpu13 Data Batch  32\n",
      "gpu10 Data Batch  33\n",
      "gpu15 Data Batch  33\n",
      "gpu2 Data Batch  34\n",
      "gpu4 Data Batch  32\n",
      "gpu11 Data Batch  33\n",
      "gpu12 Data Batch  32\n",
      "gpu3 Data Batch  33\n",
      "gpu9 Data Batch  33\n",
      "gpu5 Data Batch  33\n",
      "gpu7 Data Batch  34\n",
      "gpu8 Data Batch  32\n",
      "gpu14 Data Batch  33\n",
      "gpu13 Data Batch  33\n",
      "gpu10 Data Batch  34\n",
      "gpu6 Data Batch  34\n",
      "gpu0 Data Batch  34\n",
      "gpu1 Data Batch  33\n",
      "gpu2 Data Batch  35\n",
      "gpu15 Data Batch  34\n",
      "gpu11 Data Batch  34\n",
      "gpu12 Data Batch  33\n",
      "gpu4 Data Batch  33\n",
      "gpu3 Data Batch  34\n",
      "gpu14 Data Batch  34\n",
      "gpu8 Data Batch  33\n",
      "gpu7 Data Batch  35\n",
      "gpu5 Data Batch  34\n",
      "gpu9 Data Batch  34\n",
      "gpu6 Data Batch  35\n",
      "gpu1 Data Batch  34\n",
      "gpu10 Data Batch  35\n",
      "gpu0 Data Batch  35\n",
      "gpu13 Data Batch  34\n",
      "gpu2 Data Batch  36\n",
      "gpu11 Data Batch  35\n",
      "gpu15 Data Batch  35\n",
      "gpu12 Data Batch  34\n",
      "gpu4 Data Batch  34\n",
      "gpu3 Data Batch  35\n",
      "gpu14 Data Batch  35\n",
      "gpu5 Data Batch  35\n",
      "gpu9 Data Batch  35\n",
      "gpu8 Data Batch  34\n",
      "gpu7 Data Batch  36\n",
      "gpu6 Data Batch  36\n",
      "gpu10 Data Batch  36\n",
      "gpu13 Data Batch  35\n",
      "gpu0 Data Batch  36\n",
      "gpu1 Data Batch  35\n",
      "gpu2 Data Batch  37\n",
      "gpu15 Data Batch  36\n",
      "gpu12 Data Batch  35\n",
      "gpu11 Data Batch  36\n",
      "gpu4 Data Batch  35\n",
      "gpu3 Data Batch  36\n",
      "gpu14 Data Batch  36\n",
      "gpu5 Data Batch  36\n",
      "gpu9 Data Batch  36\n",
      "gpu8 Data Batch  35\n",
      "gpu6 Data Batch  37\n",
      "gpu7 Data Batch  37\n",
      "gpu10 Data Batch  37\n",
      "gpu1 Data Batch  36\n",
      "gpu2 Data Batch  38\n",
      "gpu13 Data Batch  36\n",
      "gpu0 Data Batch  37\n",
      "gpu12 Data Batch  36\n",
      "gpu4 Data Batch  36\n",
      "gpu11 Data Batch  37\n",
      "gpu15 Data Batch  37\n",
      "gpu3 Data Batch  37\n",
      "gpu5 Data Batch  37\n",
      "gpu14 Data Batch  37\n",
      "gpu7 Data Batch  38\n",
      "gpu8 Data Batch  36\n",
      "gpu6 Data Batch  38\n",
      "gpu10 Data Batch  38\n",
      "gpu9 Data Batch  37\n",
      "gpu1 Data Batch  37\n",
      "gpu2 Data Batch  39\n",
      "gpu0 Data Batch  38\n",
      "gpu12 Data Batch  37\n",
      "gpu13 Data Batch  37\n",
      "gpu11 Data Batch  38\n",
      "gpu15 Data Batch  38\n",
      "gpu4 Data Batch  37\n",
      "gpu5 Data Batch  38\n",
      "gpu3 Data Batch  38\n",
      "gpu14 Data Batch  38\n",
      "gpu7 Data Batch  39\n",
      "gpu6 Data Batch  39\n",
      "gpu9 Data Batch  38\n",
      "gpu10 Data Batch  39\n",
      "gpu8 Data Batch  37\n",
      "gpu1 Data Batch  38\n",
      "gpu0 Data Batch  39\n",
      "gpu13 Data Batch  38\n",
      "gpu2 Data Batch  40\n",
      "gpu12 Data Batch  38\n",
      "gpu4 Data Batch  38\n",
      "gpu11 Data Batch  39\n",
      "gpu15 Data Batch  39\n",
      "gpu5 Data Batch  39\n",
      "gpu3 Data Batch  39\n",
      "gpu14 Data Batch  39\n",
      "gpu7 Data Batch  40\n",
      "gpu9 Data Batch  39\n",
      "gpu1 Data Batch  39\n",
      "gpu8 Data Batch  38\n",
      "gpu10 Data Batch  40\n",
      "gpu6 Data Batch  40\n",
      "gpu0 Data Batch  40\n",
      "gpu2 Data Batch  41\n",
      "gpu12 Data Batch  39\n",
      "gpu13 Data Batch  39\n",
      "gpu11 Data Batch  40\n",
      "gpu15 Data Batch  40\n",
      "gpu4 Data Batch  39\n",
      "gpu5 Data Batch  40\n",
      "gpu3 Data Batch  40\n",
      "gpu7 Data Batch  41\n",
      "gpu14 Data Batch  40\n",
      "gpu9 Data Batch  40\n",
      "gpu1 Data Batch  40\n",
      "gpu10 Data Batch  41\n",
      "gpu8 Data Batch  39\n",
      "gpu6 Data Batch  41\n",
      "gpu0 Data Batch  41\n",
      "gpu2 Data Batch  42\n",
      "gpu12 Data Batch  40\n",
      "gpu13 Data Batch  40\n",
      "gpu11 Data Batch  41\n",
      "gpu5 Data Batch  41\n",
      "gpu4 Data Batch  40\n",
      "gpu15 Data Batch  41\n",
      "gpu3 Data Batch  41\n",
      "gpu7 Data Batch  42\n",
      "gpu1 Data Batch  41\n",
      "gpu14 Data Batch  41\n",
      "gpu9 Data Batch  41\n",
      "gpu10 Data Batch  42\n",
      "gpu6 Data Batch  42\n",
      "gpu0 Data Batch  42\n",
      "gpu8 Data Batch  40\n",
      "gpu2 Data Batch  43\n",
      "gpu13 Data Batch  41\n",
      "gpu12 Data Batch  41\n",
      "gpu11 Data Batch  42\n",
      "gpu15 Data Batch  42\n",
      "gpu5 Data Batch  42\n",
      "gpu3 Data Batch  42\n",
      "gpu4 Data Batch  41\n",
      "gpu1 Data Batch  42\n",
      "gpu7 Data Batch  43\n",
      "gpu9 Data Batch  42\n",
      "gpu14 Data Batch  42\n",
      "gpu8 Data Batch  41\n",
      "gpu6 Data Batch  43\n",
      "gpu0 Data Batch  43\n",
      "gpu10 Data Batch  43\n",
      "gpu13 Data Batch  42\n",
      "gpu2 Data Batch  44\n",
      "gpu11 Data Batch  43\n",
      "gpu12 Data Batch  42\n",
      "gpu4 Data Batch  42\n",
      "gpu5 Data Batch  43\n",
      "gpu3 Data Batch  43\n",
      "gpu15 Data Batch  43\n",
      "gpu7 Data Batch  44\n",
      "gpu9 Data Batch  43\n",
      "gpu14 Data Batch  43\n",
      "gpu1 Data Batch  43\n",
      "gpu6 Data Batch  44\n",
      "gpu8 Data Batch  42\n",
      "gpu0 Data Batch  44\n",
      "gpu10 Data Batch  44\n",
      "gpu11 Data Batch  44\n",
      "gpu2 Data Batch  45\n",
      "gpu13 Data Batch  43\n",
      "gpu12 Data Batch  43\n",
      "gpu15 Data Batch  44\n",
      "gpu5 Data Batch  44\n",
      "gpu3 Data Batch  44\n",
      "gpu4 Data Batch  43\n",
      "gpu7 Data Batch  45\n",
      "gpu14 Data Batch  44\n",
      "gpu1 Data Batch  44\n",
      "gpu9 Data Batch  44\n",
      "gpu6 Data Batch  45\n",
      "gpu0 Data Batch  45\n",
      "gpu10 Data Batch  45\n",
      "gpu8 Data Batch  43\n",
      "gpu11 Data Batch  45\n",
      "gpu12 Data Batch  44\n",
      "gpu2 Data Batch  46\n",
      "gpu13 Data Batch  44\n",
      "gpu15 Data Batch  45\n",
      "gpu4 Data Batch  44\n",
      "gpu5 Data Batch  45\n",
      "gpu3 Data Batch  45\n",
      "gpu7 Data Batch  46\n",
      "gpu14 Data Batch  45\n",
      "gpu6 Data Batch  46\n",
      "gpu1 Data Batch  45\n",
      "gpu9 Data Batch  45\n",
      "gpu0 Data Batch  46\n",
      "gpu10 Data Batch  46\n",
      "gpu8 Data Batch  44\n",
      "gpu11 Data Batch  46\n",
      "gpu2 Data Batch  47\n",
      "gpu13 Data Batch  45\n",
      "gpu12 Data Batch  45\n",
      "gpu15 Data Batch  46\n",
      "gpu4 Data Batch  45\n",
      "gpu3 Data Batch  46\n",
      "gpu7 Data Batch  47\n",
      "gpu14 Data Batch  46\n",
      "gpu5 Data Batch  46\n",
      "gpu6 Data Batch  47\n",
      "gpu9 Data Batch  46\n",
      "gpu0 Data Batch  47\n",
      "gpu1 Data Batch  46\n",
      "gpu10 Data Batch  47\n",
      "gpu8 Data Batch  45\n",
      "gpu11 Data Batch  47\n",
      "gpu2 Data Batch  48\n",
      "gpu15 Data Batch  47\n",
      "gpu12 Data Batch  46\n",
      "gpu13 Data Batch  46\n",
      "gpu4 Data Batch  46\n",
      "gpu3 Data Batch  47\n",
      "gpu14 Data Batch  47\n",
      "gpu6 Data Batch  48\n",
      "gpu9 Data Batch  47\n",
      "gpu5 Data Batch  47\n",
      "gpu7 Data Batch  48\n",
      "gpu0 Data Batch  48\n",
      "gpu1 Data Batch  47\n",
      "gpu10 Data Batch  48\n",
      "gpu8 Data Batch  46\n",
      "gpu11 Data Batch  48\n",
      "gpu12 Data Batch  47\n",
      "gpu13 Data Batch  47\n",
      "gpu4 Data Batch  47\n",
      "gpu15 Data Batch  48\n",
      "gpu2 Data Batch  49\n",
      "gpu9 Data Batch  48\n",
      "gpu3 Data Batch  48\n",
      "gpu5 Data Batch  48\n",
      "gpu14 Data Batch  48\n",
      "gpu7 Data Batch  49\n",
      "gpu0 Data Batch  49\n",
      "gpu6 Data Batch  49\n",
      "gpu10 Data Batch  49\n",
      "gpu1 Data Batch  48\n",
      "gpu8 Data Batch  47\n",
      "gpu11 Data Batch  49\n",
      "gpu12 Data Batch  48\n",
      "gpu13 Data Batch  48\n",
      "gpu4 Data Batch  48\n",
      "gpu3 Data Batch  49\n",
      "gpu9 Data Batch  49\n",
      "gpu2 Data Batch  50\n",
      "gpu15 Data Batch  49\n",
      "gpu6 Data Batch  50\n",
      "gpu7 Data Batch  50\n",
      "gpu0 Data Batch  50\n",
      "gpu14 Data Batch  49\n",
      "gpu5 Data Batch  49\n",
      "gpu10 Data Batch  50\n",
      "gpu1 Data Batch  49\n",
      "gpu11 Data Batch  50\n",
      "gpu8 Data Batch  48\n",
      "gpu12 Data Batch  49\n",
      "gpu15 Data Batch  50\n",
      "gpu13 Data Batch  49\n",
      "gpu9 Data Batch  50\n",
      "gpu3 Data Batch  50\n",
      "gpu2 Data Batch  51\n",
      "gpu4 Data Batch  49\n",
      "gpu6 Data Batch  51\n",
      "gpu0 Data Batch  51\n",
      "gpu7 Data Batch  51\n",
      "gpu5 Data Batch  50\n",
      "gpu14 Data Batch  50\n",
      "gpu10 Data Batch  51\n",
      "gpu1 Data Batch  50\n",
      "gpu12 Data Batch  50\n",
      "gpu11 Data Batch  51\n",
      "gpu8 Data Batch  49\n",
      "gpu4 Data Batch  50\n",
      "gpu13 Data Batch  50\n",
      "gpu9 Data Batch  51\n",
      "gpu6 Data Batch  52\n",
      "gpu15 Data Batch  51\n",
      "gpu3 Data Batch  51\n",
      "gpu2 Data Batch  52\n",
      "gpu5 Data Batch  51\n",
      "gpu14 Data Batch  51\n",
      "gpu7 Data Batch  52\n",
      "gpu0 Data Batch  52\n",
      "gpu10 Data Batch  52\n",
      "gpu1 Data Batch  51\n",
      "gpu12 Data Batch  51\n",
      "gpu8 Data Batch  50\n",
      "gpu11 Data Batch  52\n",
      "gpu6 Data Batch  53\n",
      "gpu13 Data Batch  51\n",
      "gpu15 Data Batch  52\n",
      "gpu4 Data Batch  51\n",
      "gpu3 Data Batch  52\n",
      "gpu2 Data Batch  53\n",
      "gpu9 Data Batch  52\n",
      "gpu0 Data Batch  53\n",
      "gpu5 Data Batch  52\n",
      "gpu10 Data Batch  53\n",
      "gpu7 Data Batch  53\n",
      "gpu1 Data Batch  52\n",
      "gpu14 Data Batch  52\n",
      "gpu12 Data Batch  52\n",
      "gpu8 Data Batch  51\n",
      "gpu11 Data Batch  53\n",
      "gpu6 Data Batch  54\n",
      "gpu4 Data Batch  52\n",
      "gpu3 Data Batch  53\n",
      "gpu13 Data Batch  52\n",
      "gpu15 Data Batch  53\n",
      "gpu9 Data Batch  53\n",
      "gpu2 Data Batch  54\n",
      "gpu7 Data Batch  54\n",
      "gpu5 Data Batch  53\n",
      "gpu14 Data Batch  53\n",
      "gpu10 Data Batch  54\n",
      "gpu0 Data Batch  54\n",
      "gpu1 Data Batch  53\n",
      "gpu12 Data Batch  53\n",
      "gpu11 Data Batch  54\n",
      "gpu8 Data Batch  52\n",
      "gpu6 Data Batch  55\n",
      "gpu4 Data Batch  53\n",
      "gpu15 Data Batch  54\n",
      "gpu9 Data Batch  54\n",
      "gpu2 Data Batch  55\n",
      "gpu3 Data Batch  54\n",
      "gpu13 Data Batch  53\n",
      "gpu5 Data Batch  54\n",
      "gpu14 Data Batch  54\n",
      "gpu1 Data Batch  54\n",
      "gpu10 Data Batch  55\n",
      "gpu7 Data Batch  55\n",
      "gpu0 Data Batch  55\n",
      "gpu12 Data Batch  54\n",
      "gpu6 Data Batch  56\n",
      "gpu8 Data Batch  53\n",
      "gpu11 Data Batch  55\n",
      "gpu2 Data Batch  56\n",
      "gpu4 Data Batch  54\n",
      "gpu13 Data Batch  54\n",
      "gpu9 Data Batch  55\n",
      "gpu5 Data Batch  55\n",
      "gpu14 Data Batch  55\n",
      "gpu3 Data Batch  55\n",
      "gpu15 Data Batch  55\n",
      "gpu10 Data Batch  56\n",
      "gpu7 Data Batch  56\n",
      "gpu0 Data Batch  56\n",
      "gpu1 Data Batch  55\n",
      "gpu12 Data Batch  55\n",
      "gpu6 Data Batch  57\n",
      "gpu11 Data Batch  56\n",
      "gpu8 Data Batch  54\n",
      "gpu2 Data Batch  57\n",
      "gpu4 Data Batch  55\n",
      "gpu5 Data Batch  56\n",
      "gpu14 Data Batch  56\n",
      "gpu9 Data Batch  56\n",
      "gpu15 Data Batch  56\n",
      "gpu3 Data Batch  56\n",
      "gpu10 Data Batch  57\n",
      "gpu13 Data Batch  55\n",
      "gpu7 Data Batch  57\n",
      "gpu0 Data Batch  57\n",
      "gpu1 Data Batch  56\n",
      "gpu12 Data Batch  56\n",
      "gpu6 Data Batch  58\n",
      "gpu8 Data Batch  55\n",
      "gpu11 Data Batch  57\n",
      "gpu2 Data Batch  58\n",
      "gpu4 Data Batch  56\n",
      "gpu14 Data Batch  57\n",
      "gpu5 Data Batch  57\n",
      "gpu13 Data Batch  56\n",
      "gpu9 Data Batch  57\n",
      "gpu15 Data Batch  57\n",
      "gpu3 Data Batch  57\n",
      "gpu10 Data Batch  58\n",
      "gpu7 Data Batch  58\n",
      "gpu1 Data Batch  57\n",
      "gpu0 Data Batch  58\n",
      "gpu12 Data Batch  57\n",
      "gpu6 Data Batch  59\n",
      "gpu2 Data Batch  59\n",
      "gpu8 Data Batch  56\n",
      "gpu4 Data Batch  57\n",
      "gpu5 Data Batch  58\n",
      "gpu14 Data Batch  58\n",
      "gpu11 Data Batch  58\n",
      "gpu13 Data Batch  57\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "gpu3 Data Batch  58\n",
      "gpu15 Data Batch  58\n",
      "gpu9 Data Batch  58\n",
      "gpu7 Data Batch  59\n",
      "gpu10 Data Batch  59\n",
      "gpu0 Data Batch  59\n",
      "gpu1 Data Batch  58\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "XOUT SHAPE (60508, 1024)\n",
      "gpu12 Data Batch  58\n",
      "XOUT SHAPE (60508, 1024)\n",
      "gpu8 Data Batch  57\n",
      "Garbage Collecting\n",
      "gpu4 Data Batch  58\n",
      "gpu5 Data Batch  59\n",
      "gpu11 Data Batch  59\n",
      "gpu13 Data Batch  58\n",
      "gpu14 Data Batch  59\n",
      "XOUT SHAPE (60508, 1024)\n",
      "Garbage Collecting\n",
      "gpu3 Data Batch  59\n",
      "XOUT SHAPE (60508, 1024)\n",
      "gpu15 Data Batch  59\n",
      "gpu9 Data Batch  59\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "XOUT SHAPE (60508, 1024)\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "gpu1 Data Batch  59\n",
      "gpu12 Data Batch  59\n",
      "gpu8 Data Batch  58\n",
      "gpu4 Data Batch  59\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "XOUT SHAPE (60508, 1024)\n",
      "XOUT SHAPE (60508, 1024)\n",
      "XOUT SHAPE (60508, 1024)\n",
      "Garbage Collecting\n",
      "gpu13 Data Batch  59\n",
      "XOUT SHAPE (60508, 1024)\n",
      "XOUT SHAPE (60508, 1024)\n",
      "XOUT SHAPE (60508, 1024)\n",
      "Garbage Collecting\n",
      "XOUT SHAPE (60508, 1024)\n",
      "XOUT SHAPE (60508, 1024)\n",
      "XOUT SHAPE (60508, 1024)\n",
      "gpu8 Data Batch  59\n",
      "XOUT SHAPE (60508, 1024)\n",
      "Garbage Collecting\n",
      "XOUT SHAPE (60508, 1024)\n",
      "CPU times: user 1.66 s, sys: 28.8 s, total: 30.5 s\n",
      "Wall time: 4min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 10: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 3: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 2: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 15: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "Using gpu device 13: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 6: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 7: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "Using gpu device 8: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 14: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 9: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using gpu device 1: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "Using gpu device 12: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "Using gpu device 5: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "Using gpu device 4: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu10 512 (8000, 1024)\n",
      "1\n",
      "gpu10 Feature Batch  0\n",
      "gpu10 Data Batch  0\n",
      "gpu3 512 (8000, 1024)\n",
      "gpu2 512 (8000, 1024)\n",
      "gpu15 512 (8000, 1024)\n",
      "gpu13 512 (8000, 1024)\n",
      "gpu6 512 (8000, 1024)\n",
      "gpu0 512 (8000, 1024)\n",
      "1\n",
      "1\n",
      "1\n",
      "gpu15 Feature Batch  0\n",
      "gpu2 Feature Batch  0\n",
      "gpu3 Feature Batch  0\n",
      "gpu2 Data Batch  0\n",
      "gpu15 Data Batch  0\n",
      "gpu3 Data Batch  0\n",
      "gpu14 512 (8000, 1024)\n",
      "gpu8 512 (8000, 1024)\n",
      "gpu7 512 (8000, 1024)\n",
      "1\n",
      "gpu13 Feature Batch  0\n",
      "gpu13 Data Batch  0\n",
      "1\n",
      "gpu6 Feature Batch  0\n",
      "gpu6 Data Batch  0\n",
      "1\n",
      "gpu0 Feature Batch  0\n",
      "gpu9 512 (8000, 1024)\n",
      "gpu0 Data Batch  0\n",
      "gpu12 512 (8000, 1024)\n",
      "gpu4 512 (8000, 1024)\n",
      "gpu5 512 (8000, 1024)\n",
      "gpu1 512 (8000, 1024)\n",
      "1\n",
      "1\n",
      "gpu8 Feature Batch  0\n",
      "gpu7 Feature Batch  0\n",
      "1\n",
      "gpu7 Data Batch  0\n",
      "gpu8 Data Batch  0\n",
      "gpu14 Feature Batch  0\n",
      "gpu14 Data Batch  0\n",
      "1\n",
      "1\n",
      "gpu12 Feature Batch  0\n",
      "gpu9 Feature Batch  0\n",
      "gpu12 Data Batch  0\n",
      "gpu9 Data Batch  0\n",
      "1\n",
      "1\n",
      "gpu5 Feature Batch  0\n",
      "gpu4 Feature Batch  0\n",
      "gpu4 Data Batch  0\n",
      "gpu5 Data Batch  0\n",
      "1\n",
      "gpu1 Feature Batch  0\n",
      "gpu1 Data Batch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 11: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/mnt/anaconda/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu11 512 (8000, 1024)\n",
      "1\n",
      "gpu11 Feature Batch  0\n",
      "gpu11 Data Batch  0\n",
      "gpu9 Data Batch  1\n",
      "gpu15 Data Batch  1\n",
      "gpu14 Data Batch  1\n",
      "gpu13 Data Batch  1\n",
      "gpu8 Data Batch  1\n",
      "gpu10 Data Batch  1\n",
      "gpu12 Data Batch  1\n",
      "gpu4 Data Batch  1\n",
      "gpu2 Data Batch  1\n",
      "gpu6 Data Batch  1\n",
      "gpu7 Data Batch  1\n",
      "gpu1 Data Batch  1\n",
      "gpu3 Data Batch  1\n",
      "gpu0 Data Batch  1\n",
      "gpu11 Data Batch  1\n",
      "gpu5 Data Batch  1\n",
      "gpu9 Data Batch  2\n",
      "gpu15 Data Batch  2\n",
      "gpu14 Data Batch  2\n",
      "gpu13 Data Batch  2\n",
      "gpu8 Data Batch  2\n",
      "gpu12 Data Batch  2\n",
      "gpu10 Data Batch  2\n",
      "gpu4 Data Batch  2\n",
      "gpu7 Data Batch  2\n",
      "gpu2 Data Batch  2\n",
      "gpu3 Data Batch  2\n",
      "gpu1 Data Batch  2\n",
      "gpu6 Data Batch  2\n",
      "gpu0 Data Batch  2\n",
      "gpu5 Data Batch  2\n",
      "gpu11 Data Batch  2\n",
      "gpu9 Data Batch  3\n",
      "gpu15 Data Batch  3\n",
      "gpu14 Data Batch  3\n",
      "gpu13 Data Batch  3\n",
      "gpu8 Data Batch  3\n",
      "gpu10 Data Batch  3\n",
      "gpu12 Data Batch  3\n",
      "gpu4 Data Batch  3\n",
      "gpu7 Data Batch  3\n",
      "gpu2 Data Batch  3\n",
      "gpu3 Data Batch  3\n",
      "gpu1 Data Batch  3\n",
      "gpu6 Data Batch  3\n",
      "gpu0 Data Batch  3\n",
      "gpu11 Data Batch  3\n",
      "gpu5 Data Batch  3\n",
      "gpu9 Data Batch  4\n",
      "gpu15 Data Batch  4\n",
      "gpu14 Data Batch  4\n",
      "gpu13 Data Batch  4\n",
      "gpu8 Data Batch  4\n",
      "gpu10 Data Batch  4\n",
      "gpu12 Data Batch  4\n",
      "gpu4 Data Batch  4\n",
      "gpu7 Data Batch  4\n",
      "gpu2 Data Batch  4\n",
      "gpu6 Data Batch  4\n",
      "gpu3 Data Batch  4\n",
      "gpu1 Data Batch  4\n",
      "gpu0 Data Batch  4\n",
      "gpu11 Data Batch  4\n",
      "gpu5 Data Batch  4\n",
      "gpu9 Data Batch  5\n",
      "gpu15 Data Batch  5\n",
      "gpu13 Data Batch  5\n",
      "gpu14 Data Batch  5\n",
      "gpu8 Data Batch  5\n",
      "gpu7 Data Batch  5\n",
      "gpu4 Data Batch  5\n",
      "gpu12 Data Batch  5\n",
      "gpu2 Data Batch  5\n",
      "gpu10 Data Batch  5\n",
      "gpu3 Data Batch  5\n",
      "gpu1 Data Batch  5\n",
      "gpu6 Data Batch  5\n",
      "gpu0 Data Batch  5\n",
      "gpu11 Data Batch  5\n",
      "gpu9 Data Batch  6\n",
      "gpu5 Data Batch  5\n",
      "gpu15 Data Batch  6\n",
      "gpu8 Data Batch  6\n",
      "gpu13 Data Batch  6\n",
      "gpu14 Data Batch  6\n",
      "gpu2 Data Batch  6\n",
      "gpu4 Data Batch  6\n",
      "gpu12 Data Batch  6\n",
      "gpu7 Data Batch  6\n",
      "gpu10 Data Batch  6\n",
      "gpu3 Data Batch  6\n",
      "gpu0 Data Batch  6\n",
      "gpu6 Data Batch  6\n",
      "gpu11 Data Batch  6\n",
      "gpu1 Data Batch  6\n",
      "gpu5 Data Batch  6\n",
      "gpu9 Data Batch  7\n",
      "gpu15 Data Batch  7\n",
      "gpu13 Data Batch  7\n",
      "gpu14 Data Batch  7\n",
      "gpu8 Data Batch  7\n",
      "gpu2 Data Batch  7\n",
      "gpu7 Data Batch  7\n",
      "gpu10 Data Batch  7\n",
      "gpu12 Data Batch  7\n",
      "gpu3 Data Batch  7\n",
      "gpu4 Data Batch  7\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "gpu6 Data Batch  7\n",
      "gpu1 Data Batch  7\n",
      "gpu11 Data Batch  7\n",
      "gpu0 Data Batch  7\n",
      "gpu5 Data Batch  7\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "XOUT SHAPE (8000, 1024)\n",
      "Garbage Collecting\n",
      "XOUT SHAPE (8000, 1024)\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "Garbage Collecting\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "Garbage Collecting\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "XOUT SHAPE (8000, 1024)\n",
      "CPU times: user 224 ms, sys: 25.7 s, total: 26 s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "W = np.random.randn(NUM_FEATURES,KMER_SIZE*4) * GAMMA\n",
    "%time X_lift_train_gpu = multigpu.conv_multi_gpu(X_train, W, feature_batch_size=4096, batch_size=1024, num_gpu=16, tag=\"train\", loc=\"/mnt/tmp\")\n",
    "%time X_lift_eval_gpu = multigpu.conv_multi_gpu(X_eval, W, feature_batch_size=4096, batch_size=1024, num_gpu=16, tag=\"val\", loc=\"/mnt/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60508, 16384)\n",
      "(8000, 16384)\n",
      "X SHAPE  (60508, 16384)\n",
      "Computing XTX\n",
      "Done Computing XTX\n",
      "Train acc 0.810686190256\n",
      "Test acc 0.896625\n",
      "Train ROC  0.896260398217\n",
      "Test ROC  0.990512434643\n",
      "Train AUPRC  0.889114350311\n",
      "Test AUPRC  0.19275353975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anaconda/lib/python3.6/site-packages/matplotlib/font_manager.py:1297: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9692c7e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEKECQl0IYQIExLoQggRJiTQhRAiTPx/+cFZmturSGYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9692c9d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9692d01dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = trainAndEvaluatePrimalModel(X_lift_train_gpu[:, :FEATS_TO_USE], \n",
    "                                  X_lift_eval_gpu[:, :FEATS_TO_USE],\n",
    "                                  y_train, y_eval, \n",
    "                                    reg=LAMBDA)\n",
    "train_roc, test_roc, train_pr_curve, test_pr_curve, train_pr_auc, test_pr_auc, yPredTrain, yPredTest = res \n",
    "train_roc_plot = plt.plot(train_roc[0], train_roc[1], label=\"train\")\n",
    "test_roc_plot = plt.plot(test_roc[0], test_roc[1], label=\"test\")\n",
    "train_roc = metrics.auc(train_roc[0], train_roc[1])\n",
    "test_roc = metrics.auc(test_roc[0], test_roc[1])\n",
    "plt.legend(handles=[train_roc_plot[0], test_roc_plot[0]])\n",
    "plt.figure()\n",
    "train_pr_curve_plot = plt.plot(train_pr_curve[0], train_pr_curve[1], label=\"train\")\n",
    "test_pr_curve_plot = plt.plot(test_pr_curve[0], test_pr_curve[1], label=\"test\")\n",
    "plt.legend(handles=[train_pr_curve_plot[0], test_pr_curve_plot[0]])\n",
    "plt.figure()\n",
    "print (\"Train ROC \", train_roc)\n",
    "print (\"Test ROC \", test_roc)\n",
    "print(\"Train AUPRC \", train_pr_auc)\n",
    "print(\"Test AUPRC \", test_pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58381084679053086"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.auc(test_roc[1], test_roc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
